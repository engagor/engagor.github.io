<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[Clarabridge Engage Dev Blog]]></title>
    <link href="/blog/tags/API.xml" rel="self"/>
    <link href="/"/>
    <updated>2019-10-02T12:26:43+00:00</updated>
    <id>/</id>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[Error: Internal Rate Limit Reached]]></title>
            <link href="/blog/2018/09/11/error-internal-rate-limit-reached"/>
            <updated>2018-09-11T10:00:00+00:00</updated>
            <id>/blog/2018/09/11/error-internal-rate-limit-reached</id>
            <content type="html"><![CDATA[<p>A while ago we wrote about <a href="/blog/2017/05/02/sliding-window-rate-limiter-redis">building a sliding window rate limiter with redis</a>. We needed this rate limiter for counting the amount of API calls we did to the <a href="https://www.instagram.com/developer/">Instagram API</a>. This has been working great for us. You might have heard of the deprecation of the Instagram API. Facebook introduced a <a href="https://developers.facebook.com/docs/instagram-api">new instagram API</a> as part of the Facebook graph API.</p>

<p>The new Instagram API uses the same <a href="https://developers.facebook.com/docs/graph-api/advanced/rate-limiting">rate limit measures</a> as the Facebook graph API (depends on the active users of your application). Our integration with the new Instagram API uses the same sliding window rate limiter. If our internal rate limit is reached we throw an exception: "Internal rate limit reached". This exception triggers a timeout, the timeout increases when the exception is thrown again.</p>

<p>When we deployed our integration we noticed that when an access token reached the internal rate limit, the tasks refused to do any calls to the Instagram API, even when it was allowed again, because our rate limiter was still holding them back. This resulted in data delays, not good!</p>

<p>If a combustion engine gets excessive fuel in the combustion chamber, the engine becomes flooded. You'll need to release the throttle to stop the flooding. This is exactly what's happening in our rate limiter.</p>

<p>Each time we do an API call, the following commands are sent to Redis (<a href="/blog/2017/05/02/sliding-window-rate-limiter-redis">We explained this in our previous blogpost</a>):</p>

<pre><code>&gt; MULTI
&gt; ZREMRANGEBYSCORE $accessToken 0 ($now - $slidingWindow)
&gt; ZRANGE $accessToken 0 -1
&gt; ZADD $accessToken $now $now
&gt; EXPIRE $accessToken $slidingWindow
&gt; EXEC
</code></pre>

<p>Do you see why the rate limiter gets "flooded"?</p>

<p>If you are thinking about the <code>ZADD</code> command, you're right!</p>

<p>Even when we're not allowed to do an API call we still add a timestamp. We knew this and we agreed that this was okay for our use case. However, we're using a lower rate limit (compared to the old Instagram API), which resulted in a lot of internal rate limit reached exceptions for busy Instagram accounts.</p>

<p>How can we solve this? It's important that we execute <code>ZRANGE</code> and <code>ZADD</code> in the same transaction. We want to avoid race conditions because the tasks that do these API calls are distributed. How can we check the result of <code>ZRANGE</code> before doing the <code>ZADD</code> command in the same transaction? <a href="https://github.com/itamarhaber">Itamar Haber</a> from <a href="https://redislabs.com/">Redis Labs</a> wrote a comment on our <a href="/blog/2017/05/02/sliding-window-rate-limiter-redis">previous blogpost</a> suggesting to <a href="https://gist.github.com/itamarhaber/254bac4283d1675c5a5569639b0322aa">use a Lua script</a> (Thanks, Itamar!). Using a Lua script we can execute Redis commands conditionally in an atomic way.</p>

<p>This is what we came up with:</p>

<pre><code class="lua">local token = KEYS[1]
local now = tonumber(ARGV[1])
local window = tonumber(ARGV[2])
local limit = tonumber(ARGV[3])

local clearBefore = now - window
redis.call('ZREMRANGEBYSCORE', token, 0, clearBefore)

local amount = redis.call('ZCARD', token)
if amount &lt; limit then
    redis.call('ZADD', token, now, now)
end
redis.call('EXPIRE', token, window)

return limit - amount
</code></pre>

<p>Let's break it down (Yeah, yeah üé∂):</p>

<ol>
<li>Assign the script arguments to variables.</li>
<li>Call <code>ZREMRANGEBYSCORE</code> to cleanup timestamps before the window.</li>
<li>Instead of <code>ZRANGE</code> we'll use <code>ZCARD</code> to know how many calls we already did.</li>
<li>Call <code>ZADD</code> when we've not reached the limit yet.</li>
<li>Call <code>EXPIRE</code> to make sure the sorted set, that holds the timestamps, gets cleaned up after the window has passed.</li>
</ol>

<p>In PHP we can evaluate the script using <a href="https://github.com/phpredis/phpredis">https://github.com/phpredis/phpredis</a>:</p>

<pre><code class="php">$this-&gt;redis-&gt;eval($script, [$key, $now, $window, $limit], 1);
</code></pre>

<p>This works great. Our tasks are now doing as much API calls as possible without flooding the rate limiter. üëèüòé</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[On-the-fly API&#039;s using Xinetd]]></title>
            <link href="/blog/2018/01/08/xinetd-APIs"/>
            <updated>2018-01-08T10:00:00+00:00</updated>
            <id>/blog/2018/01/08/xinetd-APIs</id>
            <content type="html"><![CDATA[<p>As developers, we often rely on exposing services in our software as an HTTP
API. Traditionally, our code would be executed from within a webserver
container. For example, PHP apps might run in
<a href="https://httpd.apache.org/">Apache</a>, or Java apps might run in
<a href="https://tomcat.apache.org/">Tomcat</a>.</p>

<p>In modern apps that strive to be self-contained, you might add a webserver
library and handle requests directly in your code instead.
<a href="http://www.tornadoweb.org">Tornado</a> for Python,
<a href="https://golang.org/pkg/net/http/">net/http</a> for Golang,
<a href="http://puma.io/">Puma</a> for Ruby or <a href="https://www.eclipse.org/jetty/">Jetty</a> for
JVM languages are examples of libraries for this.</p>

<p>Any of these options are typically fine, but sometimes you just want something
much, much simpler. Fortunately, it turns out Linux already comes with
everything you need. First, we need a problem to solve though.</p>

<p>At CX Social we deal with a lot of data. We need to do some maintenance work in
order to keep this data relevant and efficient. What we don't want is to
interfere with the processing we do for our users. We'd rather err on the side
of caution and only run these maintenance jobs when we are sure that servers
aren't currently experiencing high loads. One way to know is by looking at load
averages.</p>

<p>Let's build a simple HTTP API that tells us whether a server is currently busy
or not.</p>

<p>The tools we'll use here are <code>xinetd</code> and plain old <code>bash</code>. Xinetd is a
replacement for the original <code>inetd</code>. This is old software. The <a href="https://github.com/xinetd-org/xinetd">GitHub
mirror</a> of Xinetd has a history going 15
years back. It is simple: it lets you write a server program where you only
need to care about the output. All the other details, like networking, logging,
access control, are taken care of.</p>

<p>First, we'll have to install Xinetd which nowadays isn't installed by default:</p>

<pre><code class="bash">$ apt-get install xinetd  # on debian
$ pacman -S xinetd        # on arch
$ yum -y install xinetd   # on those other distros
</code></pre>

<p>Next, we'll need to do some configuration. I added following line to my
<code>/etc/services</code>:</p>

<pre><code>load_avg   9876/tcp
</code></pre>

<p>Then I added a file <code>/etc/xinet.d/load_avg</code> with the following contents:</p>

<pre><code>service load_avg
{
  flags = REUSE
  socket_type = stream
  protocol = tcp
  port = 9876
  wait = no
  user = nobody
  server = /data/load_avg
  log_on_failure += USERID
  disable = no
}
</code></pre>

<p>Some comments here. The <code>service load_avg</code> maps to what I added in
<code>/etc/services</code>, the <code>server = ...</code> will be the script that will be called when
a connection is made.</p>

<p>So, let's write the script itself. We'll be using plain bash. If the load
average is fine we'll return a <code>200 OK response</code>. If not, we'll return a <code>503
Service Unavailable</code> instead.</p>

<pre><code class="bash">#!/bin/bash

http_response() {
  local http_code="$1"
  local message="$2"

  local length=${#message}

  echo -en "${http_code}\r\n"
  echo -en "Content-Type: text/plain\r\n"
  echo -en "Content-Length: ${length}\r\n"
  echo -en "\r\n"
  echo -en "${message}"
  echo -en "\r\n"
}

http_200() {
  http_response "HTTP/1.1 200 OK" "200; $1"
}

http_503() {
  http_response "HTTP/1.1 503 Service Unavailable" "503; $1"
}

load_average=$(uptime | awk '{print $8 * 100}')
acceptable_load=$(nproc | awk '{print $1 * 100}')

if [ ${load_average} -gt ${acceptable_load} ]; then
  http_503 ${load_average}
else
  http_200 ${load_average}
fi
</code></pre>

<p>Let's break it up piece by piece. We start with a couple of functions that help
us construct a valid HTTP response. We can get the length of a value in bash
with <code>${#variable}</code> which is how we set the <code>length</code> variable. For the
rest, nothing particularly interesting is going on.</p>

<p>Next, we get the load average from the <code>uptime</code> command. Bash doesn't have good
support for float values so we get around that by multiplying with <code>100</code> which
lets us compare with <code>-gt</code> later on.</p>

<p>To calculate the acceptable load we cut some corners and simplify things a
little bit: <code>nproc</code> gives us the number of cores in the system so we use that
again multiplying by <code>100</code> so we can compare. So a <code>4</code> core machine would
accept a load of <code>4</code>. I don't love that solution but as an example it's good
enough. In a real setup you would add a little bit of extra margin.</p>

<p>After reloading Xinetd you can use any web client to access
<a href="http://hostname:9876">http://hostname:9876</a>.</p>

<h2 id="improvements">Improvements</h2>

<p>There are a couple of things we can do to improve upon this. We can extract the
<code>http_*</code> functions so we can easily source them as a library in other scripts.
We could render the response as JSON to make parsing the result neater on the
client side.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Often we really do require the capabilities of a full-blown development
environment to implement the features we need. In other situations we can get
away with a simple approach. Xinetd has been around for a very long time and
hides exactly the complexities we'd rather avoid having to deal with.</p>

<p>This technique can be used in interesting combinations. For example, you could
use it with <a href="http://www.haproxy.org/">HAProxy</a> health checks by using a
<code>httpchk</code> rather than a regular <code>tcp-check</code>. Say you have HAProxy in front of
an <a href="https://www.elastic.co/">Elasticsearch</a> cluster to automatically spread
searches. You could use our <code>load_avg</code> script above to exclude busy nodes
automatically.  Or say you have a MySQL setup with a handful of replicas for
reading and you use HAProxy to load balance these. You can write a simple
script that checks the <code>seconds_behind_master</code> value and excludes replicas that
are lagging.</p>

<p>Give it a try, see what you can come up with, and share your experiences in the
comment section below!</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Real-Time Webhooks API: Secure an Internship with us]]></title>
            <link href="/blog/2017/09/27/internship-webhooks-api"/>
            <updated>2017-09-27T11:00:00+00:00</updated>
            <id>/blog/2017/09/27/internship-webhooks-api</id>
            <content type="html"><![CDATA[<p>Are you a student looking for an internship for Spring 2018? We have a project involving real-time API's and webhooks that you might find interesting. Read on to know what we do here at CX Social and what the project is about.</p>

<h2 id="what-do-we-do%3F">What do we do?</h2>

<p>The Clarabridge CX Social team builds a customer care tool for social media. Our clients use our software to be able to respond to the incoming questions and complaints on their Facebook pages, Twitter accounts, Instagram profiles, a.o. These clients often have a high volume of messages, on several social profiles. We try to make those people‚Äôs lives easier by offering automation tools, smart routing of messages and reply suggestions, among others.
<a href="https://developers.engagor.com/team">Read more about what we do</a>.</p>

<p>As of February 2018, we have room for one or more enthusiastic interns to join us for (at least) a couple of weeks <em>(preferably 4 days a week, any time between February 2017 to June 2018)</em>, to work as part of the CX Social development team.
As an intern you are an integral part of the R&amp;D team working on different parts of the application using technologies like PHP, React, MySQL, Redis, memcached, ElasticSearch, RabbitMQ, a.o. The team consists of a designer, front-end developer, data scientist, and several system engineers &amp; full-stack web developers.
We are looking for a student with interest and knowledge of mainly back-end technologies, and some front-end knowledge.</p>

<p>Want to know more about what it‚Äôs like to do an internship here? Read about <a href="https://engagor.github.io/blog/2017/06/01/internship-gheerwijn-cx-social-developer/">Gheerwijn‚Äôs experiences</a> or the <a href="https://engagor.github.io/blog/2017/06/30/internship-achievements/">Achievements project intern Cedric is currently working on</a>.</p>

<h2 id="the-project%3A-webhooks-api">The Project: Webhooks API</h2>

<p>CX Social has an Rest (oAuth JSON) API used by several of our clients. Its documentation is publicly available on our <a href="https://developers.engagor.com">developer site</a> so have a look to see what‚Äôs possible with it.<br />
Its uses include displaying important social profile metrics on own websites, two-way syncing of data from the CX Social CRM to other (in-house or 3rd party) CRM‚Äôs (like Salesforce, a.o.). It‚Äôs also being used to display curated social mentions on own sites, or to combine data from CX Social with data from other tools on internal dashboards.</p>

<p>Today, the API is used in a <code>PULL</code> model only, where clients (periodically) request information from our API. This internship project involves a significant update to allow <code>PUSH</code> webhooks to be send to our clients.<br />
Clients have been requesting this feature, and are eager to start using it, to be notified of new data (e.g. new tweets), or updates to data (e.g. when a certain social contact‚Äôs information is filled in) in real-time.
The project would take inspiration from the <a href="https://developers.facebook.com/docs/graph-api/webhooks">Facebook Webhooks API</a>, <a href="https://dev.twitter.com/webhooks">Twitter Webhooks API</a>, or <a href="https://api.slack.com/custom-integrations/outgoing-webhooks">Slack‚Äôs Outgoing Webhooks API</a> and take into account other <a href="https://restful.io/webhooks-dos-and-dont-s-what-we-learned-after-integrating-100-apis-d567405a3671">common do's and don'ts regarding webhooks</a>.</p>

<p>It consists of the following features:</p>

<ul>
<li>Creating &amp; updating webhook-subscriptions (defining which webhooks should be delivered where). 

<ul>
<li>This should be possible via an API, as well as a web-interface;</li>
<li>Configured delivery URL‚Äôs should be checked for ownership by verification with configured handshake;</li>
<li>Configured delivery URL‚Äôs should be checked for validity of their SSL certificates;</li>
<li>Several types of subscriptions will be needed (i.e. subscribing to ‚Äúaccount‚Äù updates, and subscribing to ‚Äúuser‚Äù updates);</li>
</ul></li>
<li>A robust webhook delivery system, consisting of:

<ul>
<li>Re-delivery when the delivery URL‚Äôs is unresponsive;</li>
<li>Trying to guarantee exactly-once delivery;</li>
<li>Signed webhook payloads, so receivers can verify the origin of the request;</li>
<li>Notifying the API user via email when their delivery URL continues to be unresponsive;</li>
</ul></li>
<li>Implementing the event-log that eventually triggers the webhooks:

<ul>
<li>Making sure changes in the CX Social code base trigger an event to the webhooks system;</li>
<li>Distribution of events to the right subscriptions</li>
</ul></li>
<li>Monitoring of the system to:

<ul>
<li>Be alerted when webhook delivery is running behind.</li>
</ul></li>
</ul>

<p><center>
<img src="/images/2017-09-27-internships-webhooks-api/slow-delivery.gif" alt="Slow Delivery" /><br />
<small>Our future clients, when their webhooks aren't delivered on time.</small>
</center></p>

<p>Together with the CX Social development team, you as an intern are responsible for choosing the right technologies &amp; architecture. For those interested in backend technologies, this will be an exciting project, that you can help shape, build and deploy to production.</p>

<h2 id="interested%3F">Interested?</h2>

<p>We are looking for someone to join us in the Gent, Belgium office of Clarabridge, located at <a href="https://www.google.be/maps/place/CX+Social/@51.0597245,3.7213322,17z/data=!3m1!4b1!4m5!3m4!1s0x47c37138e71c8617:0x314cae371e7de8a5!8m2!3d51.0597245!4d3.7235209">Grauwpoort 1, 9000 Gent</a>.
Does this seem like a fun challenge for you? Please reach out to <a href="&#x6d;&#97;&#105;l&#x74;&#x6f;&#58;&#106;&#x75;&#x72;&#114;&#105;a&#x61;&#110;&#46;p&#x65;&#x72;&#115;&#121;&#x6e;&#x40;&#99;&#108;a&#x72;&#x61;&#98;&#114;&#x69;&#x64;&#103;&#101;&#x2e;&#x63;&#111;&#109;">jurriaan.persyn@clarabridge.com</a> with your details and we can set-up an interview to see if there‚Äôs a fit.</p>

<p><center>
<img src="/images/2017-09-27-internships-webhooks-api/thumbs.jpg" alt="Toppie" /><br />
<small>Our future clients, when you've implemented this cool feature.</small>
</center></p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Building a sliding window rate limiter with Redis]]></title>
            <link href="/blog/2017/05/02/sliding-window-rate-limiter-redis"/>
            <updated>2017-05-02T14:00:00+00:00</updated>
            <id>/blog/2017/05/02/sliding-window-rate-limiter-redis</id>
            <content type="html"><![CDATA[<p>For our Instagram crawler we needed a system to keep track of the amount of API calls we did to prevent us from hitting the rate limits. We could of course perform our HTTP requests without checking rate limits upfront, and wait until we get a <code>429 OAuthRateLimitException</code> from Instagram, but that would exhaust our tokens and block us from talking efficiently to their API.</p>

<p><img src="/images/2017-05-02-sliding-window-rate-limiter-redis/429.jpg" alt="Too many cats" /></p>

<blockquote>
  <p>All rate limits on the Instagram Platform are controlled separately for each access token, and on a sliding 1-hour window.</p>
  
  <p><a href="https://www.instagram.com/developer/limits">Instagram API rate Limits</a></p>
</blockquote>

<p>We're allowed to do 5000 API calls per access token each hour.</p>

<p><img src="/images/2017-05-02-sliding-window-rate-limiter-redis/slidingwindow.png" alt="Sliding window ratelimiting visualisation" /></p>

<p>Every point on the axis represents an API call. The sliding window is an hour in this case. Every time we do an API call we add the timestamp (in microseconds) of the API call to a list. In pseudocode:</p>

<pre><code class="js">timestamps.push(Date.now());
</code></pre>

<p>When we're about to do an API call in our crawler we need to check if we're allowed to do one:</p>

<ol>
<li>How many calls did we do in the last hour?</li>
</ol>

<pre><code class="js">callsInTheLastHour = timestamps.filter(timestamp =&gt; timestamp &gt; now - slidingWindow);
count = callsInTheLastHour.length
</code></pre>

<ol start="2">
<li>How many can we still do?</li>
</ol>

<p>After we calculated the amount of API calls we did in the last hour we can calculate the remaining API calls:</p>

<pre><code class="js">remaining = maxCallsPerHour - count;
</code></pre>

<p>Let's say we did <code>4413</code> API calls in the last hour then we're allowed to do <code>587</code> more at this moment.</p>

<p>Great, we got our algorithm. Now we need some kind of database to store a list of timestamps grouped per access token. Maybe we could use MySQL or PostgreSQL? Yes, we could but then we would need a system that periodically removes outdated timestamps since neither MySQL or PostgreSQL allow us to set a time to life on a row. What about <a href="http://memcached.org/">Memcached</a>? Yes, that's also an option. Sadly Memcached doesn't have the concept of an array or list (we could serialize an array using our favourite programming language). We can do better. What about <a href="https://redis.io/">Redis</a>? Yes, I like where this is going. Redis is a key/value store that supports lists, sets, sorted sets and more.</p>

<p>We're ready to translate our algorithm to Redis commands. Assuming you already have Redis installed, start a server: <code>$ redis-server</code>. If you're on a mac, you can just <code>$ brew install redis</code> to get it.</p>

<p>We're going to use a <a href="https://redis.io/commands/#sorted_set">sorted set</a> to hold our timestamps because it fits our needs.</p>

<pre><code>&gt; MULTI
&gt; ZREMRANGEBYSCORE $accessToken 0 ($now - $slidingWindow)
&gt; ZRANGE $accessToken 0 -1
&gt; ZADD $accessToken $now $now
&gt; EXPIRE $accessToken $slidingWindow
&gt; EXEC
</code></pre>

<p>Let's break it down:</p>

<ul>
<li><code>MULTI</code> to mark the start of a transaction block. Subsequent commands will be queued for atomic execution using <code>EXEC</code>.</li>
<li><code>ZREMRANGEBYSCORE $accessToken 0 ($now - $slidingWindow)</code> to remove API call timestamps that were done before the start of the window.</li>
<li><code>ZRANGE $accessToken 0 -1</code> to get a list of all API call timestamps that happened during the window.</li>
<li><code>ZADD $accessToken $now $now</code> to add a log for the current API call that we're about to do.</li>
<li><code>EXPIRE $accessToken $slidingWindow</code> to reset the expiry date for this sorted set of timestamps (for the current OAuth Token).</li>
<li><code>EXEC</code> will execute all previously queued commands and restore the connection state to normal.</li>
</ul>

<p>Instead of using the actual OAuth access tokens (and duplicating them to Redis), you might want to use an identifier or hash of the token instead as <code>$accessToken</code>. It serves as the key for our Redis sorted set. Also note that, in the same transaction as reading the list of timestamps, we <em>add</em> a new timestamp to the list (the <code>ZADD</code> command). We do this because this is being used in a distributed context (we have many workers performing API calls), and we don't want to write when we already exceeded our limits.</p>

<p>In PHP this might look like this:</p>

<pre><code class="php">// composer require predis/predis
require_once __DIR__ . '/vendor/autoload.php';

$maxCallsPerHour = 5000;
$slidingWindow = 3600;

$now = microtime(true);
$accessToken = md5('access-token');

$client = new Predis\Client();
$client-&gt;multi();
$client-&gt;zrangebyscore($accessToken, 0, $now - $slidingWindow);
$client-&gt;zrange($accessToken, 0, -1);
$client-&gt;zadd($accessToken, $now, $now);
$client-&gt;expire($accessToken, $slidingWindow);
$result = $client-&gt;exec();

// The second command inside the transaction was ZRANGE,
// which returns a list of timestamps within the last hour.
$timestamps = $result[1];

$remaining = max(0, $maxCallsPerHour - count($timestamps));

if ($remaining &gt; 0) {
    echo sprintf('%s: Allowed and %d remaining', $now, $remaining) . PHP_EOL;
} else {
    echo sprintf('%s: Not allowed', $now) . PHP_EOL;
}
</code></pre>

<p>To conclude all of this, and to make this work within our codebase, we put this all nicely in a class, behind an interface <code>RateLimiter</code>:</p>

<pre><code class="php">&lt;?php

namespace CXSocial\RateLimiter;

interface RateLimiter
{
    /**
     * Request the remaining ratelimit points
     *
     * @param RateLimitedResource $rateLimitedResource
     *
     * @throws SorryRateLimitUnavailable
     *
     * @return int
     */
    public function remaining(RateLimitedResource $rateLimitedResource);
}
</code></pre>

<p>This allows us to write code that doesn't couple to implemention too much. This has been working like a charm for us! We're huge fans.</p>

<p><img src="/images/2017-05-02-sliding-window-rate-limiter-redis/fan-limit.gif" alt="HUGE FAN" /></p>
]]></content>
        </entry>
    </feed>