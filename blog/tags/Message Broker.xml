<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[Clarabridge Engage Dev Blog]]></title>
    <link href="/blog/tags/Message Broker.xml" rel="self"/>
    <link href="/"/>
    <updated>2019-07-05T08:33:08+00:00</updated>
    <id>/</id>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[Distributed Processing via RabbitMQ]]></title>
            <link href="/blog/2017/01/07/distributed-processing-via-rabbit-mq"/>
            <updated>2017-01-07T08:00:00+00:00</updated>
            <id>/blog/2017/01/07/distributed-processing-via-rabbit-mq</id>
            <content type="html"><![CDATA[<p>Looking at <a href="https://stackshare.io/clarabridge-cx-social/web-application-stack">the tech stack of our CX Social product</a>, there's tens of components involved, and this post will go into detail about one of the most central components of our system: our RabbitMQ service.</p>

<p>RabbitMQ, or at least the concept of "Message Brokers" it implements, is central to the way we capture and digest the hundreds of social media messages we track each second, but also in how we throw around workload and tasks. Actually, it's so central we often take it for granted. So, let's take a step back and see why we use it ...</p>

<h2 id="what-is-a-queueing-system%3F">What is a Queueing System?</h2>

<p>Almost too simple to explain, a queueing system is a service where you can pile up a bunch of things to do (tasks) or messages to process (social media tweets etc. in our case). Different processes put messages on the queue (publish) while multiple other processes (consumers), possibly on other servers, read from these queues to e.g. execute a certain process.</p>

<p><center><img src="/images/2017-01-07-distributed-processing-via-rabbit-mq/queue.png" alt="What Is A Queue?" /></center></p>

<p>At Clarabridge CX Social, we use <a href="https://www.rabbitmq.com/">RabbitMQ</a>, but there's also <a href="https://kafka.apache.org/">Apache Kafka</a> or <a href="https://aws.amazon.com/sqs/">Amazon SQS</a> as often used alternatives.</p>

<p>Below is a screenshot of our RabbitMQ dashboard, showing a.o. about 3000 messages per second being processed.</p>

<p><img src="/images/2017-01-07-distributed-processing-via-rabbit-mq/rabbitmq-dashboard.png" alt="RabbitMQ Dashboard" /></p>

<h2 id="so%2C-what%27s-cool-about-queues%3F">So, What's Cool About Queues?</h2>

<h3 id="1.-do-stuff-async-and-handle-peaks">1. Do Stuff Async and Handle Peaks</h3>

<p>If at any point in our code we can procrastinate, we try to do so. If it's not super important to execute a certain function immediately, we push a message onto one of our RabbitMQ queues containing enough information to execute the function later, potentially by someone else. Easy. And lazy.</p>

<p>An example where we do this, is in the processing of webhooks for Facebook. For every like or comment that happens on one of the Facebook Pages that our CX Social clients own, Facebook sends us a real-time update containing who commented/liked which post. This information needs to be added to our clients' inboxes as soon as possible, but it's not vital that that's done in the same webhook-request that Facebook sends us. So, this page just pushes whatever information it gets from Facebook onto a queue. And an army of consumers for this queue turns these messages in e.g. comment objects to add to our data cluster.<br />
Whenever a Facebook post we monitor turns out to be hugely popular, and hundreds of post interactions per second is no exception, this queue serves both as a buffer (so we can handle these peak moments) and as a distributor (so multiple processes can massage and index the data).</p>

<p>Other common use cases include emailing or notifying several people. Say you have an online shop, and you want to notify a whole bunch of subscribers as soon as you add a new item to the inventory. Instead of sending these notifications in the same web request that the admin adds a product in, you push the notification-job on a queue, and let a different process send the actual emails or push notifications. Your initial request ("Add product x") stays fast, while all necessary emails are sent in the background.</p>

<h3 id="2.-split-up-complex-problems">2. Split up Complex Problems</h3>

<p>Queues are also particularly handy to split up heavy tasks into smaller, more manageable chunks of work. By using queues as the glue between these steps, you create more visibility into this chain of events.</p>

<p>One such chain that is vital to CX Social is the processing of a new incoming message (a tweet, an Instagram photo, etc.). Whenever a new messages is capture by our data crawling systems, there's several steps we need to do to get it to our clients, including:</p>

<ol>
<li>Checking which of our clients are interested in the message by matching it to the set-up of their accounts.<br />
(E.g. does it contain any of the keywords they're monitoring? Is it from a social profile they own?)</li>
<li>Resolving any of the urls in the post, as to get more details about the linked sites.</li>
<li>Computing the language the post's text is in.</li>
<li>Making an estimated guess of what the sentiment of the post could be.</li>
<li>Predict any labels that the client uses often for this particular post.</li>
<li>Indexing it to our main data cluster (ElasticSearch).</li>
<li>Predicting a possible reply for the post, if actionable.</li>
<li>Sending a notification to logged in users to their interfaces update with the new data.</li>
</ol>

<p>Each step of this process involves different services, of which some might be external, or slow, or down. By splitting this big chunk of work into smaller steps that are executed in sequence (each step generates an event that the next step listens to), we have better control over the execution of these steps. In addition, each step is simpler to monitor and thus debug (both in resource usage as speed).</p>

<h3 id="3.-give-certain-jobs-priorities">3. Give Certain Jobs Priorities</h3>

<p>By using different queues for different types of tasks, and by playing around with the amount of consumer-processes you have running for a certain queue, you have control over the priority of the tasks you push to this service, and different queues and types of tasks don't affect each other.</p>

<h3 id="4.-cross-service-communication">4. Cross-Service Communication</h3>

<p>We also use RabbitMQ in case different services need to talk to each other. At Clarabridge CX Social we have a service for real-time communication to a user's browser using websockets (via node.js/Socket.io). Every other service in our cluster can just send their messages there via RabbitMQ.
If a certain php process needs to send a real-time notification to a certain logged in user, the php process publishes an event to a RabbitMQ queue. A node.js server will then consume the event, and passes it on the client via socket.io.<br />
Using RabbitMQ as the intermediate we allow services written in a multitude of different languages to talk to each other.</p>

<h3 id="5.-monitoring-made-easy">5. Monitoring Made Easy</h3>

<p>A benefit of architecting your application this way, is that your Message Broker becomes an important and easy service to monitor, giving early indications when problems arise. As soon as a certain queue is growing beyond its expected volume, it's often an indication of a process that is slower than expected, or fully down.</p>

<p>If you monitor ...</p>

<ul>
<li>the amount of messages on a queue at any time;</li>
<li>the age of the oldest messages on a queue;</li>
<li>the rate of publishing to a queue;</li>
<li>the rate of consuming from a queue;</li>
</ul>

<p>... you have a very good indication of the health and performance of your application.</p>

<p><img src="/images/2017-01-07-distributed-processing-via-rabbit-mq/serverdensity-dashboard.png" alt="ServerDensity Dashboard" /></p>
]]></content>
        </entry>
    </feed>