<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[CX Social Dev Blog]]></title>
    <link href="/blog/categories/Redis.xml" rel="self"/>
    <link href="/"/>
    <updated>2018-09-28T08:19:28+00:00</updated>
    <id>/</id>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[Error: Internal Rate Limit Reached]]></title>
            <link href="/blog/2018/09/11/error-internal-rate-limit-reached"/>
            <updated>2018-09-11T10:00:00+00:00</updated>
            <id>/blog/2018/09/11/error-internal-rate-limit-reached</id>
            <content type="html"><![CDATA[<p>A while ago we wrote about <a href="/blog/2017/05/02/sliding-window-rate-limiter-redis">building a sliding window rate limiter with redis</a>. We needed this rate limiter for counting the amount of API calls we did to the <a href="https://www.instagram.com/developer/">Instagram API</a>. This has been working great for us. You might have heard of the deprecation of the Instagram API. Facebook introduced a <a href="https://developers.facebook.com/docs/instagram-api">new instagram API</a> as part of the Facebook graph API.</p>

<p>The new Instagram API uses the same <a href="https://developers.facebook.com/docs/graph-api/advanced/rate-limiting">rate limit measures</a> as the Facebook graph API (depends on the active users of your application). Our integration with the new Instagram API uses the same sliding window rate limiter. If our internal rate limit is reached we throw an exception: "Internal rate limit reached". This exception triggers a timeout, the timeout increases when the exception is thrown again.</p>

<p>When we deployed our integration we noticed that when an access token reached the internal rate limit, the tasks refused to do any calls to the Instagram API, even when it was allowed again, because our rate limiter was still holding them back. This resulted in data delays, not good!</p>

<p>If a combustion engine gets excessive fuel in the combustion chamber, the engine becomes flooded. You'll need to release the throttle to stop the flooding. This is exactly what's happening in our rate limiter.</p>

<p>Each time we do an API call, the following commands are sent to Redis (<a href="/blog/2017/05/02/sliding-window-rate-limiter-redis">We explained this in our previous blogpost</a>):</p>

<pre><code>&gt; MULTI
&gt; ZREMRANGEBYSCORE $accessToken 0 ($now - $slidingWindow)
&gt; ZRANGE $accessToken 0 -1
&gt; ZADD $accessToken $now $now
&gt; EXPIRE $accessToken $slidingWindow
&gt; EXEC
</code></pre>

<p>Do you see why the rate limiter gets "flooded"?</p>

<p>If you are thinking about the <code>ZADD</code> command, you're right!</p>

<p>Even when we're not allowed to do an API call we still add a timestamp. We knew this and we agreed that this was okay for our use case. However, we're using a lower rate limit (compared to the old Instagram API), which resulted in a lot of internal rate limit reached exceptions for busy Instagram accounts.</p>

<p>How can we solve this? It's important that we execute <code>ZRANGE</code> and <code>ZADD</code> in the same transaction. We want to avoid race conditions because the tasks that do these API calls are distributed. How can we check the result of <code>ZRANGE</code> before doing the <code>ZADD</code> command in the same transaction? <a href="https://github.com/itamarhaber">Itamar Haber</a> from <a href="https://redislabs.com/">Redis Labs</a> wrote a comment on our <a href="/blog/2017/05/02/sliding-window-rate-limiter-redis">previous blogpost</a> suggesting to <a href="https://gist.github.com/itamarhaber/254bac4283d1675c5a5569639b0322aa">use a Lua script</a> (Thanks, Itamar!). Using a Lua script we can execute Redis commands conditionally in an atomic way.</p>

<p>This is what we came up with:</p>

<pre><code class="lua">local token = KEYS[1]
local now = tonumber(ARGV[1])
local window = tonumber(ARGV[2])
local limit = tonumber(ARGV[3])

local clearBefore = now - window
redis.call('ZREMRANGEBYSCORE', token, 0, clearBefore)

local amount = redis.call('ZCARD', token)
if amount &lt; limit then
    redis.call('ZADD', token, now, now)
end
redis.call('EXPIRE', token, window)

return limit - amount
</code></pre>

<p>Let's break it down (Yeah, yeah üé∂):</p>

<ol>
<li>Assign the script arguments to variables.</li>
<li>Call <code>ZREMRANGEBYSCORE</code> to cleanup timestamps before the window.</li>
<li>Instead of <code>ZRANGE</code> we'll use <code>ZCARD</code> to know how many calls we already did.</li>
<li>Call <code>ZADD</code> when we've not reached the limit yet.</li>
<li>Call <code>EXPIRE</code> to make sure the sorted set, that holds the timestamps, gets cleaned up after the window has passed.</li>
</ol>

<p>In PHP we can evaluate the script using <a href="https://github.com/phpredis/phpredis">https://github.com/phpredis/phpredis</a>:</p>

<pre><code class="php">$this-&gt;redis-&gt;eval($script, [$key, $now, $window, $limit], 1);
</code></pre>

<p>This works great. Our tasks are now doing as much API calls as possible without flooding the rate limiter. üëèüòé</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Building a sliding window rate limiter with Redis]]></title>
            <link href="/blog/2017/05/02/sliding-window-rate-limiter-redis"/>
            <updated>2017-05-02T14:00:00+00:00</updated>
            <id>/blog/2017/05/02/sliding-window-rate-limiter-redis</id>
            <content type="html"><![CDATA[<p>For our Instagram crawler we needed a system to keep track of the amount of API calls we did to prevent us from hitting the rate limits. We could of course perform our HTTP requests without checking rate limits upfront, and wait until we get a <code>429 OAuthRateLimitException</code> from Instagram, but that would exhaust our tokens and block us from talking efficiently to their API.</p>

<p><img src="/images/2017-05-02-sliding-window-rate-limiter-redis/429.jpg" alt="Too many cats" /></p>

<blockquote>
  <p>All rate limits on the Instagram Platform are controlled separately for each access token, and on a sliding 1-hour window.</p>
  
  <p><a href="https://www.instagram.com/developer/limits">Instagram API rate Limits</a></p>
</blockquote>

<p>We're allowed to do 5000 API calls per access token each hour.</p>

<p><img src="/images/2017-05-02-sliding-window-rate-limiter-redis/slidingwindow.png" alt="Sliding window ratelimiting visualisation" /></p>

<p>Every point on the axis represents an API call. The sliding window is an hour in this case. Every time we do an API call we add the timestamp (in microseconds) of the API call to a list. In pseudocode:</p>

<pre><code class="js">timestamps.push(Date.now());
</code></pre>

<p>When we're about to do an API call in our crawler we need to check if we're allowed to do one:</p>

<ol>
<li>How many calls did we do in the last hour?</li>
</ol>

<pre><code class="js">callsInTheLastHour = timestamps.filter(timestamp =&gt; timestamp &gt; now - slidingWindow);
count = callsInTheLastHour.length
</code></pre>

<ol start="2">
<li>How many can we still do?</li>
</ol>

<p>After we calculated the amount of API calls we did in the last hour we can calculate the remaining API calls:</p>

<pre><code class="js">remaining = maxCallsPerHour - count;
</code></pre>

<p>Let's say we did <code>4413</code> API calls in the last hour then we're allowed to do <code>587</code> more at this moment.</p>

<p>Great, we got our algorithm. Now we need some kind of database to store a list of timestamps grouped per access token. Maybe we could use MySQL or PostgreSQL? Yes, we could but then we would need a system that periodically removes outdated timestamps since neither MySQL or PostgreSQL allow us to set a time to life on a row. What about <a href="http://memcached.org/">Memcached</a>? Yes, that's also an option. Sadly Memcached doesn't have the concept of an array or list (we could serialize an array using our favourite programming language). We can do better. What about <a href="https://redis.io/">Redis</a>? Yes, I like where this is going. Redis is a key/value store that supports lists, sets, sorted sets and more.</p>

<p>We're ready to translate our algorithm to Redis commands. Assuming you already have Redis installed, start a server: <code>$ redis-server</code>. If you're on a mac, you can just <code>$ brew install redis</code> to get it.</p>

<p>We're going to use a <a href="https://redis.io/commands/#sorted_set">sorted set</a> to hold our timestamps because it fits our needs.</p>

<pre><code>&gt; MULTI
&gt; ZREMRANGEBYSCORE $accessToken 0 ($now - $slidingWindow)
&gt; ZRANGE $accessToken 0 -1
&gt; ZADD $accessToken $now $now
&gt; EXPIRE $accessToken $slidingWindow
&gt; EXEC
</code></pre>

<p>Let's break it down:</p>

<ul>
<li><code>MULTI</code> to mark the start of a transaction block. Subsequent commands will be queued for atomic execution using <code>EXEC</code>.</li>
<li><code>ZREMRANGEBYSCORE $accessToken 0 ($now - $slidingWindow)</code> to remove API call timestamps that were done before the start of the window.</li>
<li><code>ZRANGE $accessToken 0 -1</code> to get a list of all API call timestamps that happened during the window.</li>
<li><code>ZADD $accessToken $now $now</code> to add a log for the current API call that we're about to do.</li>
<li><code>EXPIRE $accessToken $slidingWindow</code> to reset the expiry date for this sorted set of timestamps (for the current OAuth Token).</li>
<li><code>EXEC</code> will execute all previously queued commands and restore the connection state to normal.</li>
</ul>

<p>Instead of using the actual OAuth access tokens (and duplicating them to Redis), you might want to use an identifier or hash of the token instead as <code>$accessToken</code>. It serves as the key for our Redis sorted set. Also note that, in the same transaction as reading the list of timestamps, we <em>add</em> a new timestamp to the list (the <code>ZADD</code> command). We do this because this is being used in a distributed context (we have many workers performing API calls), and we don't want to write when we already exceeded our limits.</p>

<p>In PHP this might look like this:</p>

<pre><code class="php">// composer require predis/predis
require_once __DIR__ . '/vendor/autoload.php';

$maxCallsPerHour = 5000;
$slidingWindow = 3600;

$now = microtime(true);
$accessToken = md5('access-token');

$client = new Predis\Client();
$client-&gt;multi();
$client-&gt;zrangebyscore($accessToken, 0, $now - $slidingWindow);
$client-&gt;zrange($accessToken, 0, -1);
$client-&gt;zadd($accessToken, $now, $now);
$client-&gt;expire($accessToken, $slidingWindow);
$result = $client-&gt;exec();

// The second command inside the transaction was ZRANGE,
// which returns a list of timestamps within the last hour.
$timestamps = $result[1];

$remaining = max(0, $maxCallsPerHour - count($timestamps));

if ($remaining &gt; 0) {
    echo sprintf('%s: Allowed and %d remaining', $now, $remaining) . PHP_EOL;
} else {
    echo sprintf('%s: Not allowed', $now) . PHP_EOL;
}
</code></pre>

<p>To conclude all of this, and to make this work within our codebase, we put this all nicely in a class, behind an interface <code>RateLimiter</code>:</p>

<pre><code class="php">&lt;?php

namespace CXSocial\RateLimiter;

interface RateLimiter
{
    /**
     * Request the remaining ratelimit points
     *
     * @param RateLimitedResource $rateLimitedResource
     *
     * @throws SorryRateLimitUnavailable
     *
     * @return int
     */
    public function remaining(RateLimitedResource $rateLimitedResource);
}
</code></pre>

<p>This allows us to write code that doesn't couple to implemention too much. This has been working like a charm for us! We're huge fans.</p>

<p><img src="/images/2017-05-02-sliding-window-rate-limiter-redis/fan-limit.gif" alt="HUGE FAN" /></p>
]]></content>
        </entry>
    </feed>